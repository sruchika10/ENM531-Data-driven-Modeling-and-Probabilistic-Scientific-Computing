{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFfzUSvzK_IK"
      },
      "source": [
        "# Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqRAnhCpK_IR"
      },
      "source": [
        "## Problem 1 [20 Points]\n",
        "\n",
        "### Subproblem 1 [10 Points]\n",
        "\n",
        "Consider a coin that comes up heads with probability $p$ and tails with probability $1-p$. Let $q_n$ be the probability of obtaining even number of heads in $n$ independent tosses. Derive a recursion that relates $q_n$ to $q_{n-1}$ and establish the formula\n",
        "$$q_n = \\frac{1+(1-2p)^n}{2}$$\n",
        "\n",
        "\n",
        "### Subproblem 2 [10 Points]\n",
        "\n",
        "Let $X$ and $Y$ have joint PDF \n",
        "$$\n",
        "f_{X,Y}(x,y) = \\begin{cases}\n",
        "C e^{-(ax+by)} & x,y \\geq 0\\\\\n",
        "0 & \\text{otherwise}\n",
        "\\end{cases},\n",
        "$$\n",
        "\n",
        "where, $a, b > 0$ are constants\n",
        "\n",
        "- Determine the constant $C$\n",
        "- Find the marginal density of $X$ and $Y$. What can you infer from them?\n",
        "- Find $\\mathbb{E}(Y \\mid X> \\frac{\\exp(a^2 + b^2)}{a^4 + b^4})$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRx-d_IuK_IS"
      },
      "source": [
        "Subproblem 1:\n",
        "To derive a recursion for $q_n$, we can use the fact that the probability of obtaining an even number of heads in $n$ independent tosses is equal to the probability of obtaining an even number of heads in $n-1$ independent tosses and then flipping tails, plus the probability of obtaining an odd number of heads in $n-1$ independent tosses and then flipping heads.\n",
        "\n",
        "Let $q_n$ be the probability of obtaining even number of heads in $n$ independent tosses, $p$ be the probability of flipping heads, and $1-p$ be the probability of flipping tails.\n",
        "\n",
        "So,$q_n$=$q_{n-1}$(1-p)+(1-$q_{n-1}$)p\n",
        "\n",
        "Rearranging the above equation and solving it, we get:\n",
        "\n",
        "Base case:\n",
        "For $n = 1$, $q_1 = p \\cdot 0 + (1-p) \\cdot 1 = 1-p$ which matches the formula.\n",
        "\n",
        "Inductive step:\n",
        "Assume that the formula holds for $n = k$: $q_k = \\frac{1+(1-2p)^k}{2}$\n",
        "\n",
        "We have to show that it holds for $n = k+1$:\n",
        "\\begin{align*}\n",
        "q_{k+1} &= pq_k + (1-p)q_{k-1} \\\\\n",
        "&= p \\cdot \\frac{1+(1-2p)^k}{2} + (1-p) \\cdot \\frac{1+(1-2p)^{k-1}}{2} \\\\\n",
        "&= \\frac{1}{2} + \\frac{p(1-2p)^k + (1-p)(1-2p)^{k-1}}{2} \\\\\n",
        "&= \\frac{1}{2} + \\frac{(1-2p)^k - p(2p-1)(1-2p)^{k-1}}{2} \\\\\n",
        "&= \\frac{1}{2} + \\frac{(1-2p)^k - (2p-1)(1-2p)^k + (2p-1)(1-2p)^k}{2} \\\\\n",
        "&= \\frac{1}{2} + \\frac{(1-2p)^k + (2p-1)(1-2p)^k}{2} \\\\\n",
        "&= \\frac{1}{2} + \\frac{(1-2p)^k(1+(2p-1))}{2} \\\\\n",
        "&= \\frac{1}{2} + \\frac{(1-2p)^k}{2} \\\\\n",
        "&= \\frac{1+(1-2p)^{k+1}}{2}\n",
        "\\end{align*}\n",
        "Therefore, the formula holds for $n = k+1$\n",
        "\n",
        "By induction, the formula holds for all positive integers $n$.\n",
        "$$q_n = \\frac{1+(1-2p)^n}{2}$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "â€‹\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpMwmEt_K_IT"
      },
      "source": [
        "SUBPROBLEM 2: PART 1:To determine the constant $C$, we use the fact that the integral of the joint PDF over the entire support must equal 1\n",
        "\n",
        "$$C \\int_0^{\\infty}\\int_0^{\\infty}e^{-(ax+by)}dxdy = 1$$\n",
        "\n",
        "$$C \\int_0^{\\infty} e^{-ax} \\left[ \\int_0^{\\infty} e^{-by} dy \\right] dx = 1$$\n",
        "\n",
        "$$C \\int_0^{\\infty} e^{-ax} \\frac{1}{b} dy dx = 1$$\n",
        "\n",
        "$$C \\left[ \\frac{1}{b} \\int_0^{\\infty} e^{-ax} dx \\right] = 1$$\n",
        "\n",
        "$$C \\left[ \\frac{1}{b} \\frac{1}{a} e^{-ax} \\right]_{x=0}^{x=\\infty} = 1$$\n",
        "\n",
        "$$C \\left[ \\frac{1}{ab} \\right] = 1$$\n",
        "\n",
        "Thus\n",
        "\n",
        "$$C =  {ab}$$\n",
        "\n",
        "So, the constant $C$ is ${ab}$\n",
        "\n",
        "Part 2:\n",
        "\n",
        "To find the marginal density of $X$, we need to integrate the joint PDF over all possible values of $Y$:\n",
        "\n",
        "$$f_X(x) = \\int_{-\\infty}^\\infty f_{X,Y}(x,y) dy = \\int_0^\\infty Ce^{-(ax+by)} dy = C\\int_0^\\infty e^{-ax}e^{-by} dy$$\n",
        "\n",
        "$$f_X(x) = Ce^{-ax}\\int_0^\\infty e^{-by} dy = Ce^{-ax}\\left[-\\frac{1}{b}e^{-by}\\right]_0^\\infty = Ce^{-ax}\\left[-\\frac{1}{b}e^{-by}\\right]_0^\\infty = \\frac{C}{b}e^{-ax}$$\n",
        "\n",
        "Similarly, we can find the marginal density of $Y$ by integrating the joint PDF over all possible values of $X$:\n",
        "\n",
        "$$f_Y(y) = \\int_{-\\infty}^\\infty f_{X,Y}(x,y) dx = \\int_0^\\infty Ce^{-(ax+by)} dx = C\\int_0^\\infty e^{-ax}e^{-by} dx$$\n",
        "\n",
        "$$f_Y(y) = Ce^{-by}\\int_0^\\infty e^{-ax} dx = Ce^{-by}\\left[-\\frac{1}{a}e^{-ax}\\right]_0^\\infty = Ce^{-by}\\left[-\\frac{1}{a}e^{-ax}\\right]_0^\\infty = \\frac{C}{a}e^{-by}$$\n",
        "\n",
        "To find the value of C, we use the property that the integral of the PDF over the entire sample space is 1.\n",
        "\n",
        "$$1 = \\int_{-\\infty}^{\\infty}f_{X,Y}(x,y)dxdy = \\int_0^\\infty \\int_0^\\infty Ce^{-(ax+by)} dxdy = C\\int_0^\\infty \\int_0^\\infty e^{-ax}e^{-by} dxdy = C\\left[-\\frac{1}{ab}e^{-ax-by}\\right]_0^\\infty = \\frac{1}{ab}$$\n",
        "\n",
        "So $C= ab$.\n",
        "\n",
        "Hence the marginal density of X is $f_X(x) = abe^{-ax}$ and marginal density of Y is $f_Y(y) = abe^{-by}$.\n",
        "\n",
        "From the marginal density of $X$ and $Y$, we can infer that they are both exponential distributions with parameters $a$ and $b$, respectively.\n",
        "\n",
        "\n",
        "From the joint PDF, we can infer that X and Y are non-negative, continuous random variables and they are independent of each other as the joint PDF can be written as the product of their marginal PDFs. Also, the joint PDF is in the form of a two-dimensional exponential distribution, which is often used to model systems where events occur independently, but at a constant average rate. Additionally, we can infer that the value of a and b determine the rate at which X and Y decrease as their values increase.\n",
        "\n",
        "PART 3:\n",
        "\n",
        "we can find the conditional PDF $f_{Y \\mid X}(y \\mid x)$.\n",
        "\n",
        "Given the joint PDF of X and Y as:\n",
        "\n",
        "\\frac{ab}{e} e^{-(ax+by)} & x,y \\geq 0\\\\\n",
        "$$f_X(x) = \\int_{-\\infty}^\\infty f_{X,Y}(x,y) dy = \\int_0^\\infty Ce^{-(ax+by)} dy = C\\int_0^\\infty e^{-ax}e^{-by} dy$$\n",
        "\n",
        "$$f_X(x) = Ce^{-ax}\\int_0^\\infty e^{-by} dy = Ce^{-ax}\\left[-\\frac{1}{b}e^{-by}\\right]_0^\\infty = Ce^{-ax}\\left[-\\frac{1}{b}e^{-by}\\right]_0^\\infty = \\frac{C}{b}e^{-ax}$$\n",
        "\n",
        "We can find the conditional PDF by dividing the joint PDF by the marginal PDF\n",
        "$$f_{Y \\mid X}(y \\mid x) = \\frac{f_{X,Y}(x,y)}{f_X(x)}$$\n",
        "So,\n",
        "$$f_{Y \\mid X}(y \\mid x) = \\frac{{ab}e^{-(ax+by)}}{{a}e^{-ax}} = {b}e^{-by} $$\n",
        "Now we can find the expectation\n",
        "$$\\mathbb{E}(Y \\mid X> \\frac{\\exp(a^2 + b^2)}{a^4 + b^4}) = \\int_{0}^{\\infty} yf_{Y \\mid X}(y \\mid x)dy $$\n",
        "$$\\mathbb{E}(Y \\mid X> \\frac{\\exp(a^2 + b^2)}{a^4 + b^4}) = {b}\\int_{0}^{\\infty} ye^{-by} dy $$\n",
        "$$\\mathbb{E}(Y \\mid X> \\frac{\\exp(a^2 + b^2)}{a^4 + b^4}) = {b}\\frac{1}{b^2}$$\n",
        "so,\n",
        "$$\\mathbb{E}(Y \\mid X> \\frac{\\exp(a^2 + b^2)}{a^4 + b^4}) = \\frac{1}{b}$$\n",
        "This is the expected value of Y given that X is greater than $\\frac{\\exp(a^2 + b^2)}{a^4 + b^4}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGVQRgVRK_IV"
      },
      "source": [
        "## Problem 2 [20 points]\n",
        "\n",
        "Let $S_1,S_2,\\ldots,S_n$ be a partition of the sample space $\\Omega$.\n",
        "- Show that for any event $A$,\n",
        "  $$\\mathbb{P}(A) = \\sum_{i=1}^n \\mathbb{P}\\left({A \\cap S_i}\\right)$$\n",
        "- Use the previous part to show that, for events $A$, $B$ and $C$,\n",
        "  $$\\mathbb{P}\\left({A}\\right) = \\mathbb{P}\\left({A \\cap B}\\right) + \\mathbb{P}\\left({A \\cap C}\\right) + \\mathbb{P}\\left({A \\cap B^c \\cap C^c}\\right) - \\mathbb{P}\\left({A \\cap B \\cap C}\\right)$$\n",
        "- Prove that for any two events $A$ and $B$, we have\n",
        "$$\\mathbb{P} (A \\cap B) \\geq \\mathbb{P}(A) + \\mathbb{P}(B) - 1$$\n",
        "- Using the above, establish the following generalization:\n",
        "$$\\mathbb{P}(A_1 \\cap A_2 \\cap \\cdots \\cap A_n) \\geq \\mathbb{P}(A_1) + \\mathbb{P}(A_2) + \\cdots + \\mathbb{P}(A_n) - (n-1)$$\n",
        "\n",
        "**[You will need to argue logically using only the axioms. Drawing a diagram is not enough.]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KobE64DyK_IW"
      },
      "source": [
        "## Answer:\n",
        "**Sub-problem 1 $:$**\n",
        "This equation is known as the Law of Total Probability. It states that the probability of an event A is equal to the sum of the probabilities of the intersections of that event with a set of mutually exclusive events, S1, S2, .., Sn whose union is the sample space.\n",
        "\n",
        "**Goal**:To find P(A)\n",
        "\n",
        "For two events A and B:\n",
        "\n",
        "$\\mathbb{P}(A) =\\mathbb{P}(A \\cap B) + \\mathbb{P}(A \\cap B^c)$\n",
        "\n",
        "Using the law of conditional probability we can write:\n",
        "\n",
        "$\\mathbb{P}(A) =\\mathbb{P}(A|B)P(B) +\\mathbb{P}(A|B^c)P(B^c)$\n",
        "\n",
        "Let A be an event and S1, S2, ..., Sn be a set of mutually exclusive events whose union is the sample space.\n",
        "\n",
        "By the definition of mutually exclusive events, we know that for any i and j, where i â‰  j, we have A âˆ© Si âˆ© Sj = âˆ….\n",
        "And ,\n",
        "\n",
        "$\\mathbb{S} = \\bigcup_{i=1}^{n} S_i$\n",
        "\n",
        "$\\mathbb A = A \\cap S = A \\cap \\left( \\bigcup_{i=1}^{n} S_i \\right) = \\bigcup_{i=1}^{n} (A \\cap S_i)$\n",
        "\n",
        "The third axiom of probability states that the probability of the union of disjoint events is equal to the sum of their individual probabilities. In other words, if we have a sample space S and a set of disjoint events S1, S2, ..., Sn such that their union is equal to S, then the probability of an event A is equal to the sum of the probabilities of the events that result from intersecting A with each of the disjoint events in the partition.\n",
        "\n",
        "\n",
        "$\\mathbb {P}(A) =\\sum\\limits_{i=1}^{n}P(A\\cap S_i) = \\sum\\limits_{i=1}^{n}P(A|S_i)P(S_i)$\n",
        "\n",
        "\n",
        "**Sub-problem2 $:$**\n",
        "\n",
        "We partition the sample space as : \n",
        "$\\Omega = (B \\cup C) \\cup (B \\cup C)^c$. \\\\\n",
        "\n",
        "We can see that $(B \\cup C)$ and $(B \\cup C)^c$ are disjoint , and also union of set with its complement is the universal set (as the event and its complement will form the entire set)\\\\\n",
        "Additionally, when we use DeMorgan's laws :\n",
        "$$(B \\cup C)^c =(B^c \\cap C^c) $$\n",
        "As we proved in the previous part i.e the law of conditional probability:\n",
        "\\begin{aligned}\n",
        "\\mathbb{P}(A) &= Î£_i \\mathbb{P}(A \\cap S_i)\\\\ \n",
        "&= \\mathbb{P}(A \\cap (B \\cup C)) + \\mathbb{P}(A \\cap (B^c \\cap C^c)) \\\\\n",
        "&= \\mathbb{P}((A \\cap B) \\cup (A \\cap C)) + \\mathbb{P}(A \\cap B^c \\cap C^c)  \\\\\n",
        "&= \\mathbb{P}(A \\cap B) + \\mathbb{P}(A \\cap C) - \\mathbb{P}((A \\cap B \\cap C) + \\mathbb{P}(A \\cap B^c \\cap C^c)\n",
        "\\end{aligned}\n",
        "\n",
        "\n",
        "The inclusion-exclusion principle states that the probability of the union of two events, $A$ and $B$, is equal to the sum of the probabilities of the events minus the probability of their intersection. This can be written as:\n",
        "\n",
        "$\\mathbb{P} (A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)$\n",
        "\n",
        "The principle holds because each element in the union of $A$ and $B$ is counted exactly once. If an element is in both $A$ and $B$, it is counted twice by $\\mathbb{P}(A) + \\mathbb{P}(B)$ but subtracted once by $\\mathbb{P}(A \\cap B)$, resulting in a total count of once. If an element is only in $A$ or $B$, it is counted once by $\\mathbb{P}(A) + \\mathbb{P}(B)$ and not subtracted by $\\mathbb{P}(A \\cap B)$, also resulting in a total count of once.\n",
        "\n",
        "Hence, the step where we subtract $$\\mathbb{P}((A \\cap B \\cap C)$$ is a correction factor\n",
        "\n",
        "\n",
        "**Sub-problem 3 $:$**\n",
        "\n",
        "We know that $A \\cap B$ is the intersection of events $A$ and $B$, and $A \\cup B$ is the union of events $A$ and $B$. \n",
        "Now,\n",
        "\n",
        "$A \\cup B$ +  $A \\cup B^c $ = S\n",
        "\n",
        "$\\mathbb{P}(A \\cup B)+\\mathbb{P}(A \\cup B ^c)=1$\n",
        "\n",
        "$\\mathbb{P}(A)+\\mathbb{P}(B)-\\mathbb{P}(A \\cap B)+\\mathbb{P}(A \\cup B)^c=1 $\n",
        "\n",
        "$\\mathbb{P}(A \\cap B)=(\\mathbb{P}(A)+\\mathbb{P}(B)-1)+\\mathbb{P}(A \\cup B)^c $\n",
        "\n",
        "$\\mathbb{P}(A \\cap B)>=(\\mathbb{P}(A)+\\mathbb{P}(B)-1)$,Given that : $\\mathbb{P}(A \\cup B)^c $is non negative(greater than or equal to zero)\n",
        "\n",
        "\n",
        "**Sub-problem 4 $:$**\n",
        "Mathematical induction is a method used to prove that a statement is true for all positive integers. The general idea is to prove the statement for the base case (usually n = 1) and then show that if the statement is true for any positive integer n, it must also be true for n + 1.\n",
        "\n",
        "Assuming that the statement\n",
        "P(A âˆ© B) â‰¥ P(A) + P(B) - 1\n",
        "is true for any two events A and B, we can use mathematical induction to prove the following generalization:\n",
        "\n",
        "Base case: $n = 2$\n",
        "\\begin{align}\n",
        "P(A_1 \\cap A_2) &= P(A_1) + P(A_2) - P(A_1 \\cup A_2) \\\n",
        "&\\ge P(A_1) + P(A_2) - 1 \\\n",
        "\\end{align}\n",
        "\n",
        "Assume that the statement holds for $n$ events:\n",
        "\\begin{align}\n",
        "P(A_1 \\cap A_2 \\cap \\dots \\cap A_n) &\\ge P(A_1) + P(A_2) + \\dots + P(A_n) - (n-1)\n",
        "\\end{align}\n",
        "\n",
        "Inductive step:\n",
        "\\begin{align}\n",
        "P(A_1 \\cap A_2 \\cap \\dots \\cap A_n \\cap A_{n+1}) &= P(A_1) + P(A_2) + \\dots + P(A_n) + P(A_{n+1}) \\\n",
        "&\\quad - P(A_1 \\cup A_2 \\cup \\dots \\cup A_n \\cup A_{n+1}) \\\n",
        "&\\ge P(A_1) + P(A_2) + \\dots + P(A_n) + P(A_{n+1}) - n \\\n",
        "\\end{align}\n",
        "\n",
        "Therefore, by induction, the statement holds for any positive integer $n$.\n",
        "\\begin{align}\n",
        "P(A_1 \\cap A_2 \\cap \\dots \\cap A_n) &\\ge P(A_1) + P(A_2) + \\dots + P(A_n) - (n - 1)\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxu4dhxBK_IX"
      },
      "source": [
        "## Problem 3 [20 Points]\n",
        "\n",
        "### Subproblem 1 [10 Points]\n",
        "\n",
        "- If $X_1,X_2,\\ldots,X_n$ are independent random variables having the same probability density function $f_X(x)$, what is the probability density function for the random variable $Y=\\text{min}\\{X_1,X_2,\\ldots,X_n\\}$?\n",
        "- Consider two continuous random variables $Y$ and $Z$ and a random variable $X$ that is equal to $Y$ with a probability $p$ and equals $Z$ with a probability $1-p$. Obtain the pdf of $X$ interms of the pdf's of $Y$ and $Z$.\n",
        "\n",
        "### Subproblem 2 [10 Points]\n",
        "\n",
        "The Laplace distribution is given by\n",
        "$$p(x | \\mu, b) = \\frac{1}{2 b} \\exp \\left(-\\frac{|x - \\mu|}{b}\\right)$$\n",
        "\n",
        "Consider a mixture of three Laplace distributions:\n",
        "$p(x) = \\alpha p_1(x) + \\beta p_2(x) + \\gamma p_3(x)$\n",
        "\n",
        "where $\\alpha, \\beta, \\gamma \\in [0,1]$ are mixture weights satisfying $\\alpha + \\beta + \\gamma = 1$ and $p_1(x)$, $p_2(x)$ and $p_3(x)$ are Laplace distributions with different parameters $(\\mu_1, b_1) \\neq (\\mu_2, b_2) \\neq (\\mu_3, b_3)$.\n",
        "\n",
        "Derive the expectation and variance of $p(x)$, analytically, using their definitions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj5jRDxpK_IX"
      },
      "source": [
        "## Answer:\n",
        "\n",
        "The cumulative distribution function of $Y = \\min{X_1, X_2, \\ldots, X_n}$ can be written as:\n",
        "\n",
        "$$F_Y(y) = P(Y \\le y) = P\\left(\\min{X_1, X_2, \\ldots, X_n} \\le y\\right) = 1 - P\\left(\\min{X_1, X_2, \\ldots, X_n} > y\\right) = 1 - \\prod_{i=1}^n P(X_i > y)$$\n",
        "\n",
        "And using the independence of $X_1, X_2, \\ldots, X_n$, we get:\n",
        "\n",
        "$$F_Y(y) = 1 - (1 - F_X(y))^n$$\n",
        "\n",
        "Where $F_X(y)$ is the cumulative distribution function of $X$.\n",
        "\n",
        "The probability density function of $Y$ can be obtained by differentiating the cumulative distribution function:\n",
        "\n",
        "$$f_Y(y) = \\frac{d}{dy} F_Y(y) = n\\cdot f_X(y)\\cdot(1-F_X(y))^{n-1}$$\n",
        "\n",
        "Where $f_X(y)$ is the probability density function of $X$.\n",
        "\n",
        "**PART B:**\n",
        "The pdf of a random variable gives us the probability of the variable taking on a specific value. When we have a combination of two random variables as in this case, the pdf of the combined variable is obtained by taking into account the probability of each component variable. In this case, $X$ can take on the value of either $Y$ or $Z$, so the pdf of $X$ is the weighted sum of the pdf's of $Y$ and $Z$, where the weights are the probabilities $p$ and $1-p$ respectively.\n",
        "\n",
        "The probability density function (pdf) of $X$ is given by the weighted sum of the pdf's of $Y$ and $Z$, where the weights are the probabilities $p$ and $1-p$ respectively:\n",
        "\n",
        "$f_X(x) = p\\cdot f_Y(x) + (1-p)\\cdot f_Z(x)$\n",
        "\n",
        "Where $f_Y(x)$ and $f_Z(x)$ are the pdf's of $Y$ and $Z$ respectively.\n",
        "\n",
        "The pdf of $X$ in terms of the pdf's of $Y$ and $Z$ is given by:\n",
        "$$f_X(x) = pf_Y(x) + (1-p)f_Z(x)$$\n",
        "\n",
        "This distribution is valid as :\n",
        "\n",
        "We know that $f_Y(x) \\geq 0$ and $f_Z(x) \\geq 0$, since they are both PDFs, and also that $0 \\leq p \\leq 1$, $X > 0$\n",
        "\n",
        "We know that since $f_Y, f_Z$ are PDFs, $\\int_{-\\infty}^{\\infty}f_Y(x) = 1$, and $\\int_{-\\infty}^{\\infty}f_Z(x) = 1$. We have for X :\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\int_{-\\infty}^{\\infty}f_X(x) dx &= \\int_{-\\infty}^{\\infty}(pf_Y(x) + (1-p)f_Z(x)) dx \\\\\n",
        "&= p\\int_{-\\infty}^{\\infty}f_Y(x)dx + (1-p)\\int_{-\\infty}^{\\infty}f_Z(x)dx \\\\\n",
        "&= p \\cdot 1 + (1-p) \\cdot 1 = 1\n",
        "\\end{aligned}\n",
        "$$\n",
        "Hence we see that $f_X$ is the required PDF.\n",
        "\n",
        "\n",
        "**SUBPROBLEM 2:**The expectation of a probability distribution is given by:\n",
        "\n",
        "$$\\mathbb{E}[x] = \\int x p(x) dx$$\n",
        "\n",
        "The variance of a probability distribution is given by:\n",
        "\n",
        "$$Var(x) = \\mathbb{E}[x^2] - \\mathbb{E}[x]^2$$\n",
        "\n",
        "Finding the  mean and variance of laplace distribution:\n",
        "$$\n",
        "f(x | \\mu, b) = \\frac{1}{2 b} \\exp \\left(-\\frac{|x - \\mu|}{b}\\right)\n",
        "$$\n",
        "\n",
        "Exxpectation substituting $Y = X - \\mu$ :\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathbb{E}[X]\n",
        "&=\\frac1{2b}\\int_{-\\infty}^\\infty y\\  e^{-\\Large\\frac{|y|}{b}}\\ dy+\\mu\\\\\n",
        "&=\\frac1{2b}\\int_{-\\infty}^0 y\\  e^{-\\Large\\frac{y}{b}}\\ dy+ \\frac1{2b}\\int_{0}^\\infty y\\  e^{-\\Large\\frac{y}{b}}\\ dy + \\mu\\\\\n",
        "&=-\\frac1{2b}\\int_{0}^\\infty y\\  e^{-\\Large\\frac{y}{b}}\\ dy+ \\frac1{2b}\\int_{0}^\\infty y\\  e^{-\\Large\\frac{y}{b}}\\ dy + \\mu \n",
        "&= \\mu\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "variance ( formula $var[X] = E[X^2] - E[X]^2$):\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbb{E}[X^2] &= \\mathbb{E}[(Y+\\mu)^2] \\\\\n",
        "&= \\mathbb{E}[Y^2] + 2\\mu\\mathbb{E}[X-\\mu] + \\mu^2 \\\\\n",
        "&= \\frac1{2b}\\int_{-\\infty}^\\infty y^2\\  e^{-\\Large\\frac{|y|}{b}}\\ dy+\\mu^2\\\\\n",
        "&=\\frac1{2b}\\int_{-\\infty}^0 y^2\\  e^{-\\Large\\frac{y}{b}}\\ dy+ \\frac1{2b}\\int_{0}^\\infty y^2\\  e^{-\\Large\\frac{y}{b}}\\ dy + \\mu^2\\\\\n",
        "&= \\frac1{b}\\int_{0}^\\infty y^2\\  e^{-\\Large\\frac{y}{b}}\\ dy + \\mu^2 \\quad \\text \\\n",
        "&= 2b^2 + \\mu^2 \\quad \n",
        "\\end{aligned} \n",
        "$$\n",
        "We know from the above formula that, $var(X) = E[X^2] - E[X]^2 = 2b^2$. \\\\\n",
        " \\\\\n",
        "\n",
        "To find the expectation and variance of the mixture distribution $p(x)$, we will use the properties of the expectation and variance for linear combinations of random variables.\n",
        "\n",
        "First, we will find the expectation of the mixture distribution:\n",
        "\n",
        "$$\\mathbb{E}[x] = \\int x p(x) dx = \\int x (\\alpha p_1(x) + \\beta p_2(x) + \\gamma p_3(x)) dx$$\n",
        "\n",
        "$$ = \\alpha \\int x p_1(x) dx + \\beta \\int x p_2(x) dx + \\gamma \\int x p_3(x) dx$$\n",
        "\n",
        "The Laplace distribution has the following expectation:\n",
        "\n",
        "$$\\mathbb{E}[x] = \\mu$$\n",
        "\n",
        "Therefore,\n",
        "\n",
        "$$\\mathbb{E}[x] = \\alpha \\mu_1 + \\beta \\mu_2 + \\gamma \\mu_3$$\n",
        "\n",
        "Now we will find the variance of the mixture distribution:\n",
        "\n",
        "$$Var(x) = \\mathbb{E}[x^2] - \\mathbb{E}[x]^2$$\n",
        "\n",
        "To find $\\mathbb{E}[x^2]$, we will use the following property for a linear combination of random variables:\n",
        "\n",
        "$$\\mathbb{E}[c_1 X_1 + c_2 X_2 + \\cdots + c_n X_n] = c_1 \\mathbb{E}[X_1] + c_2 \\mathbb{E}[X_2] + \\cdots + c_n \\mathbb{E}[X_n]$$\n",
        "\n",
        "Therefore,\n",
        "\n",
        "$$\\mathbb{E}[x^2] = \\alpha \\mathbb{E}[x_1^2] + \\beta \\mathbb{E}[x_2^2] + \\gamma \\mathbb{E}[x_3^2]$$\n",
        "\n",
        "The Laplace distribution has the following second moment:\n",
        "\n",
        "$$\\mathbb{E}[x^2] = \\mu^2 + b^2$$\n",
        "\n",
        "Therefore,\n",
        "\n",
        "The variance of $p(x)$ is given by\n",
        "$$\\text{Var}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2$$\n",
        "\n",
        "To calculate $\\mathbb{E}[X^2]$, we have\n",
        "$$\\mathbb{E}[X^2] = \\int x^2 p(x) dx = \\int x^2 (\\alpha p_1(x) + \\beta p_2(x) + \\gamma p_3(x)) dx$$\n",
        "$$= \\alpha \\int x^2 p_1(x) dx + \\beta \\int x^2 p_2(x) dx + \\gamma \\int x^2 p_3(x) dx$$\n",
        "\n",
        "Again, since $p_1(x), p_2(x), p_3(x)$ are all Laplace distributions, we know that their variances are equal to $2b_1^2, 2b_2^2, 2b_3^2$, respectively. Therefore,\n",
        "$$\\mathbb{E}[X^2] = \\alpha (\\mu_1^2 + 2b_1^2) + \\beta (\\mu_2^2 + 2b_2^2) + \\gamma (\\mu_3^2 + 2b_3^2)$$\n",
        "\n",
        "Thus,\n",
        "$$\\text{Var}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 = \\alpha (\\mu_1^2 + 2b_1^2) + \\beta (\\mu_2^2 + 2b_2^2) + \\gamma (\\mu_3^2 + 2b_3^2) - (\\alpha \\mu_1 + \\beta \\mu_2 + \\gamma \\mu_3)^2$$\n",
        "\n",
        "So the expectation and variance of $p(x)$ are:\n",
        "$$\\mathbb{E}[X] = \\alpha \\mu_1 + \\beta \\mu_2 + \\gamma \\mu_3$$\n",
        "\n",
        "Variance is:\n",
        "$$\\text{Var}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 = \\alpha (\\mu_1^2 + 2b_1^2) + \\beta (\\mu_2^2 + 2b_2^2) + \\gamma (\\mu_3^2 + 2b_3^2) - (\\alpha \\mu_1 + \\beta \\mu_2 + \\gamma \\mu_3)^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swX5gSGNK_IY"
      },
      "source": [
        "## Problem 4 [20 Points]\n",
        "\n",
        "As mentioned in class the Gaussian has nice properties which makes it a fundamental tool in statistical infererence. The standard normal $\\mathcal{N}(\\mathbf{x}; \\mathbf{\\mu}, \\mathbf{\\Sigma})$ is defined as\n",
        "\n",
        "$$\n",
        "    \\mathcal{N}(\\mathbf{x}; \\mathbf{\\mu}, \\mathbf{\\Sigma}) = \\frac{1}{\\sqrt{(2 \\pi)^n |\\mathbf{\\Sigma}|}} \\exp \\left[ -\\frac{1}{2} (\\mathbf{x} - \\mathbf{\\mu})^\\top \\Sigma^{-1} (\\mathbf{x} - \\mathbf{\\mu}) \\right]\n",
        "$$\n",
        "\n",
        "- Prove that if $x \\in \\mathbb{R}^d$ is normally distributed, every affine transformation $y = A x + b$ also has a Gaussian distribution. Find its mean and covariance.\n",
        "- Analytically find the KL divergence $\\mathbb{KL}(P || Q)$ between two multivariate normal distributions $p(x) \\sim \\mathcal{N}(\\mathbf{x}; \\mathbf{\\mu}_1, \\mathbf{\\Sigma}_1)$ and $q(x) \\sim \\mathcal{N}(\\mathbf{x}; \\mathbf{\\mu}_2, \\mathbf{\\Sigma}_2)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKsS-NcDK_IZ"
      },
      "source": [
        "**SUBPROBLEM 1:**\n",
        "Let $y = A x + b$, where $A$ is a $d \\times n$ matrix and $b$ is a $d$-dimensional vector. We want to find the mean and covariance of $y$.\n",
        "\n",
        "Mean:\n",
        "\\begin{align*}\n",
        "\\mathbb{E}[y] &= \\mathbb{E}[A x + b] \\\n",
        "&= A \\mathbb{E}[x] + b \\\n",
        "&= A \\mathbf{\\mu} + b\n",
        "\\end{align*}\n",
        "\n",
        "Covariance:\n",
        "\\begin{align*}\n",
        "\\mathbb{Cov}[y] &= \\mathbb{Cov}[A x + b] \\\n",
        "&= \\mathbb{Cov}[A x] \\\n",
        "&= A \\mathbb{Cov}[x] A^\\top \\\n",
        "&= A \\mathbf{\\Sigma} A^\\top\n",
        "\\end{align*}\n",
        "\n",
        "**SUBPROBLEM 2:**\n",
        "The KL divergence for a continuous random variable is given by:\n",
        "\n",
        "$KL[P || Q] = \\int_{X} p(x)\\ln \\frac{p(x)}{q(x)}dx$\n",
        "\n",
        "Applied to the multivariate normal distributions in (1), the KL divergence yields:\n",
        "\n",
        "$KL[P || Q] = \\int_{\\mathbb{R}^{n}} N(x; \\mu_{1}, \\Sigma_{1})\\ln \\frac{N(x; \\mu_{1}, \\Sigma_{1})}{N(x; \\mu_{2}, \\Sigma_{2})}dx$\n",
        "\n",
        "$= \\langle \\ln \\frac{N(x; \\mu_{1}, \\Sigma_{1})}{N(x; \\mu_{2}, \\Sigma_{2})} \\rangle_{p(x)}$\n",
        "\n",
        "When we use the probability density function of the multivariate normal distribution, this becomes:\n",
        "\n",
        "$KL[P || Q] = \\langle \\ln \\frac{N(x; \\mu_{1}, \\Sigma_{1})}{N(x; \\mu_{2}, \\Sigma_{2})} \\rangle_{p(x)}$\n",
        "\n",
        "$= \\langle \\ln \\frac{\\frac{1}{\\sqrt{(2\\pi)^{n}|\\Sigma_{1}|}}\\exp\\left[-\\frac{1}{2}(x - \\mu_{1})^{T}\\Sigma_{1}^{-1}(x - \\mu_{1})\\right]}{\\frac{1}{\\sqrt{(2\\pi)^{n}|\\Sigma_{2}|}}\\exp\\left[-\\frac{1}{2}(x - \\mu_{2})^{T}\\Sigma_{2}^{-1}(x - \\mu_{2})\\right]} \\rangle_{p(x)}$\n",
        "\n",
        "$= \\frac{1}{2} \\langle \\ln \\frac{|\\Sigma_{2}|}{|\\Sigma_{1}|} - (x - \\mu_{1})^{T}\\Sigma_{1}^{-1}(x - \\mu_{1}) + (x - \\mu_{2})^{T}\\Sigma_{2}^{-1}(x - \\mu_{2}) \\rangle_{p(x)}$\n",
        "\n",
        "Using the fact that $x=tr(x)$ if $x$ is a scalar, and the trace property $tr(ABC)=tr(BCA)$, we have $tr(x)= x$\n",
        "\n",
        "$= \\frac{1}{2}\\left\\langle \\ln \\left| \\Sigma_2 \\right| - \\left| \\Sigma_1 \\right| - tr\\left[\\Sigma^{-1}_1 (x - \\mu_1)(x - \\mu_1)^T\\right] + tr\\left[\\Sigma^{-1}_2 (x - \\mu_2)(x - \\mu_2)^T\\right]\\right\\rangle_{p(x)}$\n",
        "\n",
        "$= \\frac{1}{2} \\cdot \\left\\langle \\ln \\left| \\Sigma_2 \\right| / \\left| \\Sigma_1 \\right| -\n",
        "\\text{tr} \\left[ \\Sigma_1^{-1} (x - \\mu_1)(x - \\mu_1)^T \\right] +\n",
        "\\text{tr} \\left[ \\Sigma_2^{-1} \\left( x x^T - 2 \\mu_2 x^T + \\mu_2 \\mu_2^T \\right) \\right] \\right\\rangle_{p(x)}$\n",
        "\n",
        "Because trace function and expected value are both linear operators, the expectation can be moved inside the trace:\n",
        "\n",
        "\\begin{aligned}\n",
        "& = \\frac{1}{2} \\Biggl( \\ln \\left| \\Sigma_2 \\right| \\left| \\Sigma_1 \\right| - tr \\left[ \\Sigma_{1}^{-1} \\left\\langle \\left( x - \\mu_1 \\right)\\left(x - \\mu_1\\right)^T \\right\\rangle p(x) \\right] \\ + tr \\left[ \\Sigma_{2}^{-1} \\left\\langle xx^T - 2 \\mu_2 x^T + \\mu_2 \\mu_2^T \\right\\rangle_{p(x)} \\right] \\Biggr)\n",
        "\\end{aligned}\n",
        "\n",
        "$=\\frac{1}{2}\\left(\\ln \\left\\vert \\Sigma_2 \\right\\vert \\left\\vert \\Sigma_1 \\right\\vert - tr\\left[\\Sigma_1^{-1} \\left\\langle (x-\\mu_1)(x-\\mu_1)^T \\right\\rangle_{p(x)}\\right] + tr\\left[\\Sigma_2^{-1} \\left(\\left\\langle xx^T \\right\\rangle_{p(x)} - 2\\left\\langle \\mu_2 x^T \\right\\rangle_{p(x)} + \\left\\langle \\mu_2\\mu_2^T \\right\\rangle_{p(x)}\\right)\\right]\\right)$\n",
        "\n",
        "Using the expectation of a linear form for the multivariate normal distribution:\n",
        "\n",
        "$x \\sim N(\\mu, \\Sigma) \\implies \\langle A x \\rangle = A \\mu$\n",
        "\n",
        "and the expectation of a quadratic form for the multivariate normal distribution:\n",
        "\n",
        "$x \\sim N(\\mu, \\Sigma) \\implies \\langle x^T A x \\rangle = \\mu^T A \\mu + tr(A \\Sigma)$\n",
        "\n",
        "the Kullback-Leibler divergence from becomes:\n",
        "\n",
        "\\begin{align*} KL[P || Q] &= \\frac{1}{2} \\left( \\ln \\left| \\Sigma_2 \\right| \\left| \\Sigma_1 \\right| - tr \\left[ \\Sigma_{1}^{-1} \\right] + tr \\left[ \\Sigma_{2}^{-1} \\left( \\Sigma_1 + \\mu_1 \\mu_1^T - 2\\mu_2 \\mu_1^T + \\mu_2 \\mu_2^T \\right) \\right] \\right) \\end{align*}\n",
        "\\begin{align*} &= \\frac{1}{2} \\left( \\ln \\left| \\Sigma_2 \\right| \\left| \\Sigma_1 \\right| - n + tr \\left[ \\Sigma_{2}^{-1} \\Sigma_1 \\right] + tr \\left[ \\left( \\mu_2 - \\mu_1 \\right)^T \\Sigma_{2}^{-1} \\left( \\mu_2 - \\mu_1 \\right) \\right] \\right) \\end{align*}\n",
        "\\begin{align*}&= \\frac{1}{2} \\left[ \\ln \\left| \\Sigma_2 \\right| \\left| \\Sigma_1 \\right| - n + tr \\left[ \\Sigma_{2}^{-1} \\Sigma_1 \\right] + \\left( \\mu_2 - \\mu_1 \\right)^T \\Sigma_{2}^{-1} \\left( \\mu_2 - \\mu_1 \\right) \\right]. \\end{align*}\n",
        "\n",
        "Finally, rearranging the terms, we get:\n",
        "\n",
        "\\begin{align*} KL[P || Q] =& \\frac{1}{2} \\left[ (\\mu_2 - \\mu_1)^T \\Sigma_{2}^{-1} (\\mu_2 - \\mu_1) + \\text{tr} \\left( \\Sigma_{2}^{-1} \\Sigma_1 \\right) - \\ln \\left| \\Sigma_1 \\right| + \\ln \\left| \\Sigma_2 \\right| - n \\right]\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plTLvWU4K_Ia"
      },
      "source": [
        "## Problem 5 [20 Points]\n",
        "\n",
        "Consider a two-dimensional random variable $z=(z_1,z_2)$ distributed as\n",
        "\n",
        "$$\n",
        "p(z_1,z_2) = \\mathcal{N}\\left(\\left[\\begin{matrix} 0 \\\\ 0 \\end{matrix}\\right],\n",
        "\\left[\\begin{matrix} 1 & 0 \\\\ 0 & 1 \\end{matrix}\\right]\\right).\n",
        "$$\n",
        "\n",
        "\n",
        "Also consider a transformation $z_1 = g_1(x_1) = x_1^3 - 6x_1^2 + 12x_1 - 8$ whose inverse mapping is $x_1 = g_1^{-1}(z_1) = z_1^{1/3} + 2$, and $z_2 = g_2(x_2) = x_2 + 1$ whose inverse mapping is $x_2 = g_2^{-1}(z_2) = z_2 - 1$. Generate $5000$ realizations for $(z_1, z_2)$ from $p(z_1,z_2)$ and compute the corresponding $(x_1, x_2)$ pairs according to the given transformation. Then, maximize the log-likelihood of the $(x_1, x_2)$ observations to estimate the parameters of the forward mapping that transforms $p(z)$ into $p(x)$ (consider a polynomial basis). Report the learned parameters, log-likelihood loss and a visualization of $p(x)$ at every step of your gradient ascent algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "643RZe3RK_Ib"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as np   \n",
        "from jax import grad, jacfwd, jit, random, vmap\n",
        "from jax.scipy.stats import multivariate_normal\n",
        "from jax.tree_util import tree_map\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCWaK_rmK_Ic"
      },
      "outputs": [],
      "source": [
        "def g_inv(z, params):\n",
        "  x1 = params[0]* np.cbrt(z[0]) + params[1]\n",
        "  #print(z[0])\n",
        "  x2 = params[2] * z[1] + params[3]\n",
        "  #print(z[1])\n",
        "  return np.array([x1, x2])\n",
        "\n",
        "def g_fwd(X,params):\n",
        "  x1=params[0]*np.power(X[0],3)+params[1]*np.power(X[0],2)+params[2]*np.power(X[0],1)+params[3]\n",
        "  x2=params[4]*np.power(X[1],3)+params[5]*np.power(X[1],2)+params[6]*np.power(X[1],1)+params[7]\n",
        "  return np.array([x1, x2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DgS0x_7K_Ic"
      },
      "outputs": [],
      "source": [
        "g_inv_vec = vmap(g_inv, in_axes=(0, None))\n",
        "g_fwd_vec = vmap(g_fwd, in_axes=(0, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxoCPAeK_Id",
        "outputId": "1c7147c9-817c-4d56-d235-07df4ef31160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.3969241   0.25045034]\n",
            " [-2.1396856   0.29204696]\n",
            " [ 1.1461986  -0.6384599 ]\n",
            " ...\n",
            " [ 0.20302461 -0.04424291]\n",
            " [ 0.56993127  0.07566901]\n",
            " [ 1.3775586   0.7038264 ]]\n",
            "(5000, 2)\n",
            "x = g_inv(z) = [[ 3.117869   -0.7495496 ]\n",
            " [ 0.7114043  -0.70795304]\n",
            " [ 3.046534   -1.6384599 ]\n",
            " ...\n",
            " [ 2.5877368  -1.0442429 ]\n",
            " [ 2.829101   -0.924331  ]\n",
            " [ 3.1126795  -0.29617357]]\n",
            "(5000, 2)\n",
            "z = g_fwd(x) = [[ 1.3969269   0.25045037]\n",
            " [-2.1396856   0.29204696]\n",
            " [ 1.1462002  -0.6384599 ]\n",
            " ...\n",
            " [ 0.20302391 -0.04424286]\n",
            " [ 0.5699291   0.07566899]\n",
            " [ 1.3775616   0.7038264 ]]\n"
          ]
        }
      ],
      "source": [
        "rng_key = random.PRNGKey(0)\n",
        "z = random.normal(rng_key, shape=(5000, 2))\n",
        "params=1, 2, 1, -1\n",
        "x = g_inv_vec(z, params)\n",
        "params1= np.array([1, -6, 12, -8, 0, 0, 1, 1])\n",
        "z_back = g_fwd_vec(x,params1)\n",
        "\n",
        "\n",
        "\n",
        "print(z)\n",
        "print(z.shape)\n",
        "print(\"x = g_inv(z) =\", x)\n",
        "print(x.shape)\n",
        "print(\"z = g_fwd(x) =\", z_back)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "Bf6djHULK_Id",
        "outputId": "1778833e-a29d-45ff-8080-eabbbaec0132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.40954202 -1.3310618 ]\n",
            " [-1.8526287  -1.5790561 ]\n",
            " [-1.3795527   1.534724  ]\n",
            " ...\n",
            " [ 0.10090402  0.5340228 ]\n",
            " [ 0.32329157 -2.323881  ]\n",
            " [ 0.74528337 -0.87408835]]\n",
            "[[ 2.742619   -2.3310618 ]\n",
            " [ 0.7718178  -2.5790563 ]\n",
            " [ 0.88678396  0.534724  ]\n",
            " ...\n",
            " [ 2.4655533  -0.4659772 ]\n",
            " [ 2.6863275  -3.323881  ]\n",
            " [ 2.9066517  -1.8740883 ]]\n",
            "[[ 0.409544   -1.3310618 ]\n",
            " [-1.8526282  -1.5790563 ]\n",
            " [-1.3795533   1.534724  ]\n",
            " ...\n",
            " [ 0.10090446  0.5340228 ]\n",
            " [ 0.32329178 -2.323881  ]\n",
            " [ 0.7452812  -0.8740883 ]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'z = g(x) [reconstructed]')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "rng_key = random.PRNGKey(1)\n",
        "z = random.normal(rng_key, (5000, 2))\n",
        "print(z)\n",
        "\n",
        "x     = g_inv_vec(z, params)\n",
        "z_rec = g_fwd_vec(x,params1)\n",
        "print(x)\n",
        "print(z_rec)\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
        "ax1.hist2d(z[:, 0], z[:, 1], bins=50, range=[(-5,5), (-5,5)], density=True)\n",
        "ax1.set_xlim(-5, 5)\n",
        "ax1.set_ylim(-5, 5)\n",
        "ax1.set_title('z ~ p(z)')\n",
        "\n",
        "ax2.hist2d(x[:, 0], x[:, 1], bins=50, range=[(-5,5), (-5,5)], density=True)\n",
        "ax2.set_xlim(-5, 5)\n",
        "ax2.set_ylim(-5, 5)\n",
        "ax2.set_title('x = g^{-1}(z)')\n",
        "\n",
        "ax3.hist2d(z_rec[:, 0], z_rec[:, 1], bins=50, range=[(-5,5), (-5,5)], density=True)\n",
        "ax3.set_xlim(-5, 5)\n",
        "ax3.set_ylim(-5, 5)\n",
        "ax3.set_title('z = g(x) [reconstructed]')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z5sSVxkK_Id",
        "outputId": "ab7f9e87-326b-4837-87a6-9f4c1b162211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log p(z) = -4.292217\n",
            "log p(x) = -4.628736\n"
          ]
        }
      ],
      "source": [
        "z = random.normal(rng_key, (2,))\n",
        "x = g_inv(z, params)\n",
        "\n",
        "mu_z = np.zeros(2)\n",
        "cov_z = np.eye(2)\n",
        "\n",
        "logp_z = multivariate_normal.logpdf(z, mean=mu_z, cov=cov_z)\n",
        "\n",
        "# Compute the Jacobian of g using automatic differentiation\n",
        "J = jacfwd(g_fwd) # this return a callable function!\n",
        "\n",
        "# Compute the log-likelihood of x using the change of variables formula\n",
        "logp_x = multivariate_normal.logpdf(g_fwd(x, params1), mean=mu_z, cov=cov_z) + \\\n",
        "         np.log(np.abs(np.linalg.det(J(x, params1))))\n",
        "\n",
        "print(\"log p(z) =\", logp_z)\n",
        "print(\"log p(x) =\", logp_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sW8ycPGK_Ie",
        "outputId": "c8810009-65d9-49d1-8e73-2e89d30423bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log p(x) = [-2.3041358 -3.2910194 -2.6540308 ... -2.4160042 -4.2445364 -1.5949955]\n"
          ]
        }
      ],
      "source": [
        "J_vec = vmap(J, in_axes=(0,None)) # returns a callable function!\n",
        "det_vec = vmap(np.linalg.det) # returns a callable function!\n",
        "rng_key=random.PRNGKey(1)\n",
        "# Generate a batch of samples\n",
        "z = random.normal(rng_key, (5000, 2))\n",
        "x = g_inv_vec(z, params)\n",
        "\n",
        "# One more sanity check..\n",
        "\n",
        "#\\log p(x) from the change of variabled formula\n",
        "print(\"log p(x) =\", multivariate_normal.logpdf(g_fwd_vec(x,params1), \n",
        "mean=np.zeros(2), \n",
        "cov=np.eye(2)) + \n",
        "np.log(np.abs(det_vec(J_vec(x,params1)))))\n",
        "# # \\log p(x) from our analytical calculation\n",
        "#print(\"log p(x) =\", multivariate_normal.logpdf(x, mean=g_fwd_vec(mu_z,1, -6, 12, -8, 0, 0, 1, 1), cov=g_inv_vec(z, 1, 2, 1, -1) ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IhTl6LuK_Ie"
      },
      "outputs": [],
      "source": [
        "z_train = random.normal(rng_key, (5000, 2))\n",
        "x_train = g_inv_vec(z_train, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMQbCvHvK_If"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def loss(params, batch):\n",
        "    return -np.mean(multivariate_normal.logpdf(g_fwd_vec(batch, params), \n",
        "                                               mean=np.zeros(2), \n",
        "                                               cov=np.eye(2)) + \n",
        "                    np.log(np.abs(det_vec(J_vec(batch,params)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZpwTsZAK_If"
      },
      "outputs": [],
      "source": [
        "grad_loss = grad(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "uTOHK1D_K_If",
        "outputId": "0848e5d0-5838-425d-a623-a8633d826a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration = 1990, loss = 2.164945363998413\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "rng_key = random.PRNGKey(0)\n",
        "# a1_est=random.normal(rng_key, (1,)) * 0.5+1\n",
        "# b1_est=random.normal(rng_key, (1,)) * 0.5-6\n",
        "# c1_est=random.normal(rng_key, (1,)) * 0.5-12\n",
        "# d1_est=random.normal(rng_key, (1,)) * 0.5-8\n",
        "# e1_est=random.normal(rng_key, (1,)) * 0.5+0\n",
        "# f1_est=random.normal(rng_key, (1,)) * 0.5+0\n",
        "# g1_est=random.normal(rng_key, (1,)) * 0.5+1\n",
        "# h1_est=random.normal(rng_key, (1,)) * 0.5+1\n",
        "params_est = params1 + random.normal(rng_key, (8,))*0.002\n",
        "# print(params_est)\n",
        "\n",
        "\n",
        "# # # Define a learning rate parameter\n",
        "lr = 0.001\n",
        "\n",
        "# # Define the gradient descent step\n",
        "def step(params, batch):\n",
        "  grads =grad_loss(params_est, batch)\n",
        "  params = tree_map(lambda x, g: x - lr*g, params_est, grads)\n",
        "  return params\n",
        "\n",
        "# # Initial parameters and training data batch\n",
        "params = params_est\n",
        "#print(params)\n",
        "batch = x_train\n",
        "\n",
        "for i in range(2000):\n",
        "    params = step(params, batch)\n",
        "    \n",
        "    # Show progress\n",
        "    if i % 10 == 0:\n",
        "        clear_output(wait=True)\n",
        "        params_est = params\n",
        "\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        plt.title(\"iteration = {}, loss = {}\".format(i, loss(params, batch)))\n",
        "        print(\"iteration = {}, loss = {}\".format(i, loss(params, batch)))\n",
        "        \n",
        "        plt.hist2d(batch[:, 0], batch[:, 1], bins=50, range=[(-5,5), (-5,5)], density=True)\n",
        "        plt.xlim(-5, 5)\n",
        "        plt.ylim(-5, 5)\n",
        "\n",
        "        x = np.arange(-5.0, 5.0, 0.05)\n",
        "        y = np.arange(-5.0, 5.0, 0.05)\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "        shape = X.shape\n",
        "        grid = np.hstack([X.reshape(-1, 1), Y.reshape(-1, 1)])\n",
        "        Z = np.exp(multivariate_normal.logpdf(g_fwd_vec(grid,params), mean=np.zeros(2),cov=np.eye(2)) + np.log(np.abs(det_vec(J_vec(grid,params)))))\n",
        "        Z = Z.reshape(shape)\n",
        "        CS = plt.contour(X, Y, Z, levels=10, lw=2)\n",
        "\n",
        "        plt.show( )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "46001093d95e05b9a104f5fe60da2f4be227a5a2b376abf000efa4e2223724e8"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}